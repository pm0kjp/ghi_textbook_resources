# Judicious Decision Making for AI Adoption: a Global Health Informatics Framework

**Version 1.0**

## Section 1: State the Problem

*State the problem clearly.  Why adopt AI?  Many B2B (business-to-business) companies are adept at making their products feel exciting, whether or not they address an organization’s most salient issues.  It is important to keep the problem statement well defined.*

1.  Why is this product beneficial?  Which important, specific, and measurable problem can this product solve for at least one significant stakeholder audience, such as patients, clinical providers, non-provider clinic workers, ministry of health leaders, or the public at large?  

> Problem statement:  
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

2) Is this important and specific problem the right problem to tackle at this time, or is there a different problem that has higher priority?

> Relative priority of the problem:
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

3. What is the risk if this product fails to solve the problem?  Is it financial risk only?  Or is there additional risk, such as to patient safety?  What is the risk if the problem is left unaddressed?

> Risks:
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

4) By what metrics will success of this product be measured?  How will leaders know if the problem being addressed has been solved, or improved to a sufficient degree?  What data exists about this problem currently, and what data will continue to be collected to allow for measurement of effectiveness?

> Data used, and its availability:
> <br/>
> <br/>
> <br/>
> <br/>
> Success metric:
> <br/>
> <br/>
> <br/>
> <br/>

5) Is this problem being presented for the first time, or with new urgency and importance by this seller, with high-pressure sales tactics?  Or was this a problem that the health system was already aware of, and the seller is accurately describing it?

> <div style="margin:0px auto; text-align: center;">←——————————————————————————————————————→</div>    
><span style="float:left">Appropriate / Accurate</span><span style="float:right">High Pressure / False Urgency</span>
<br/>

## Section 2: Understand the Product

*Understand the product details.  AI vendors sell a number of different kinds of solutions.  What is being sold, for how long, and how safe and useful is it for your particular use case?  Is it a “black box” that will foster dependency on a vendor?  Are there regulatory concerns?*

6) What is the business model of this product?  What, precisely, is being sold, for how long, and with what kind of contract?  Is it software with a yearly license agreement?  API access to a model?  Is the product a dataset?  Is it consulting?  


> What is being sold and its location: 
> <br/>
> <br/>
> <br/>
> Cost:
> <br/>
> <br/>
> <br/>
> Duration / Details:
> <br/>
> <br/>
> <br/>

7) Does this product require the use of data from the health system?  Will data be transmitted or shared with the vendor?  Will data cross international borders?  Will system data be used to improve or change a model for other customers?  What are the legal and ethical implications?  What are the privacy protections in place?

> Data that will be used by the product:
> <br/>
> <br/>
> <br/>
> Leaving the health system?
> <br/>
> <br/>
> <br/>
> Leaving the country?
> <br/>
> <br/>
> <br/>
> Legal / ethical / privacy  questions to consider:
> <br/>
> <br/>
> <br/>

8) What kind of data or clinical reality was used to create the product?  Is there bias in the data, such as a racial, linguistic, sex, or age differences that might make the product inappropriate for deployment?

> Data used for making the product:
> <br/>
> <br/>
> <br/>
> Differences with our population:
> <br/>
> <br/>
> <br/>

9) How explainable, maintainable, and configurable is the product being sold?  Will the health system need to continue to pay for configuration changes, adjustments, updated data, system updates, fine tuning, or other expenses that are not explicitly indicated already?

> Configurable by purchaser?
> <br/>
> <br/>
> <br/>
> Configurable by vendor?
> <br/>
> <br/>
> <br/>
> Cost?
> <br/>
> <br/>
> <br/>

10) What data availability assumptions does this product make?  For example, does this readmission risk model assume that the health system has bedside monitors or a particular granularity of height and weight data for pediatric patients?

> Data availability assumptions:
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

11) What assumptions of technical capacity does this product make?  For example, does this forecasting and alerting product assume that physicians carry hospital-secured smart devices that can be remotely erased?

> Technical capacity assumptions:
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

## Section 3: Stakeholder engagement

*Involve key stakeholders early and often in the decision-making process.  All informatics solutions require change management skills, and this is especially true in the case of AI adoption.* 

12) What changes in workflow would this product require from frontline workers?  What do they think of this product?  How would they directly benefit from its use?  How will they be trained in its use?  How will they be incentivized to use it?

> Workflow changes:
> <br/>
> <br/>
> <br/>
> Frontline stakeholder buy-in considerations:
> <br/>
> <br/>
> <br/>

13) What are the potential public opinion risks and benefits associated with adopting the use of this product?  If the public found out about this product and its cost, what would the reaction be?

> Public stakeholder buy-in considerations:
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

14) Does the health system have sufficient information security, network engineering, platform engineering, data science, legal, and audit capability and staffing to ensure that the terms of the purchase contract are enacted and that the product is properly installed and operational, in accordance with law and best practices?

> Staffing and support stakeholder considerations:

> <br/>
> <br/>
> <br/>
> <br/>
> <br/>
> <br/>

-------
<a href="https://creativecommons.org">Judicious Decision Making for AI Adoption: a Global Health Informatics Framework</a> © 2025 by <a href="https://creativecommons.org">K. Joy Payton</a> is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC BY-NC-ND 4.0</a><img src="https://mirrors.creativecommons.org/presskit/icons/cc.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;"><img src="https://mirrors.creativecommons.org/presskit/icons/by.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;"><img src="https://mirrors.creativecommons.org/presskit/icons/nc.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;"><img src="https://mirrors.creativecommons.org/presskit/icons/nd.svg" alt="" style="max-width: 1em;max-height:1em;margin-left: .2em;">